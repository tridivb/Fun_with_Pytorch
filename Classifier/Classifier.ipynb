{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional Dependency**: Visdom for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 0.4.1 Device: cuda\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import visdom\n",
    "\n",
    "viz = visdom.Visdom()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using PyTorch version:', torch.__version__, 'Device:', device)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, bathSize, outputDims):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, outputDims)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        layer1Conv = self.conv1(input)\n",
    "        layer1 = self.maxpool1(self.relu1(self.bn1(layer1Conv)))\n",
    "        layer2Conv = self.conv2(layer1)\n",
    "        layer2 = self.maxpool2(self.relu2(self.bn2(layer2Conv)))\n",
    "        layer3 = self.maxpool3(self.relu3(self.bn3(self.conv3(layer2))))\n",
    "        layer4 = self.maxpool4(self.relu4(self.bn4(self.conv4(layer3))))\n",
    "        layer5 = layer4.view(layer4.size(0), -1)\n",
    "        layer5 = F.dropout(F.relu(self.fc1(layer5)), p=0.3, training=self.training)\n",
    "        out = self.fc2(layer5)\n",
    "        \n",
    "        return F.log_softmax(out, dim=1), self.conv1.weight.data, self.conv2.weight.data, layer1Conv, layer2Conv    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainLoader, optimizer, epoch, logInterval=100):\n",
    "    model.train()\n",
    "    for batchIdx, (data, target) in enumerate(trainLoader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, _, _, _, _ = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batchIdx % logInterval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'\n",
    "                  .format(epoch, batchIdx * len(data), len(trainLoader.dataset), \n",
    "                          100. * batchIdx / len(trainLoader), loss.item())\n",
    "                 )\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testLoader, optimizer, confMat=None):\n",
    "    model.eval()\n",
    "    testLoss = 0.0\n",
    "    correct = 0.0\n",
    "    data = None\n",
    "    with torch.no_grad():\n",
    "        for data, target in testLoader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output, convWeights1, convWeights2, layer1, layer2 = model(data)\n",
    "            testLoss += F.nll_loss(output, target).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            if confMat is not None:\n",
    "                for idx in range(target.size()[0]):\n",
    "                    confMat[target[idx], pred[idx].item()] += 1\n",
    "            \n",
    "    testLoss /= len(testLoader.dataset)\n",
    "    accuracy = 100 * (correct / len(testLoader.dataset))\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "          .format(testLoss, correct, len(testLoader.dataset), accuracy))\n",
    "    return testLoss, accuracy, convWeights1, convWeights2, layer1, layer2, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visLine(yVal, xVal, lab, title, winLine=None):\n",
    "    viz.line(X=np.array([xVal]), \n",
    "             Y=np.array([yVal]), \n",
    "             win=winLine, \n",
    "             name=lab,\n",
    "             update='append',\n",
    "             opts=dict(title=title,\n",
    "                       showlegend=True)\n",
    "            )\n",
    "    \n",
    "def visHeatMap(mat, title):\n",
    "    ''' https://matplotlib.org/gallery/images_contours_and_fields/image_annotated_heatmap.html\n",
    "    '''\n",
    "    viz.heatmap(\n",
    "        X=np.flipud(mat),\n",
    "        opts=dict(\n",
    "            columnnames=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'],\n",
    "            rownames=['truck', 'ship', 'horse', 'frog', 'dog', 'deer', 'cat', 'bird', 'automobile', 'airplane'],\n",
    "            title=title,\n",
    "        ))\n",
    "\n",
    "def visImageGrids(data, win, title):\n",
    "    b, c, h, w = data.shape\n",
    "    for idx in range(0,c,3):\n",
    "        if idx == 0:\n",
    "            grid = data[:,0:3,:,:]\n",
    "        else:\n",
    "            if (c%3 == 0 and idx+3 < c+1) or (idx+3 < c):\n",
    "                grid = torch.cat((grid, data[:,idx:idx+3,:,:]))\n",
    "            else:\n",
    "                noPads = idx+3-c\n",
    "                pad = torch.cat((data[:,idx:c,:,:], torch.zeros(b, noPads, h, w).to(device)),dim=1)\n",
    "                grid = torch.cat((grid, pad))\n",
    "    grid = F.interpolate(grid, size=([32,32]))\n",
    "    nrows = min(int(grid.shape[0]/2),16)\n",
    "    if win:\n",
    "        win = viz.images(grid, nrow=nrows, padding=2, win=win, opts=dict(title=title))\n",
    "    else:\n",
    "        win = viz.images(grid, nrow=nrows, padding=2, opts=dict(title=title))\n",
    "    return win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalModel(lr, opt, batchSize, outputDims, winLine):\n",
    "    '''Helper function to evaluate the model\n",
    "    '''\n",
    "    model = Net(batchSize, outputDims).to(device)\n",
    "        \n",
    "    confusionMatrix = None\n",
    "    winImg = None\n",
    "    winFil1 = None\n",
    "    winFil2 = None\n",
    "    winConv1 = None\n",
    "    winConv2 = None\n",
    "    \n",
    "    if opt == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.01)\n",
    "    elif opt == 'ADAM':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9,0.999), weight_decay=0.01)\n",
    "        \n",
    "    for epoch in range(1, epochs+1):\n",
    "        trainLoss = train(model, trainLoader, optimizer, epoch, logInterval=500)\n",
    "        \n",
    "        if epoch == epochs:\n",
    "            confusionMatrix = torch.zeros((10,10)).to(device)\n",
    "        testLoss, testAcc, convWeights1, convWeights2, layer1Conv, layer2Conv, data = test(\n",
    "            model, testLoader, optimizer, confusionMatrix)\n",
    "        \n",
    "        visLine(trainLoss, epoch-1, opt, 'Train Loss', winLine[0])\n",
    "        visLine(testLoss, epoch-1, opt, 'Test Loss', winLine[1])\n",
    "        visLine(testAcc, epoch-1, opt, 'Test Accuracy', winLine[2])\n",
    "        \n",
    "        if epoch == 1:\n",
    "            winImg = visImageGrids(data[0:32,:,:,:], winImg, 'Test Images')\n",
    "        winFil1 = visImageGrids(convWeights1, winFil1, 'Trained Layer1 Filters for ' + opt)\n",
    "        winFil2 = visImageGrids(convWeights2, winFil2, 'Trained Layer2 Filters for ' + opt)\n",
    "        winConv1 = visImageGrids(layer1Conv[0:32,:,:,:], winConv1, 'Layer1 Convolution output for ' + opt)\n",
    "        winConv2 = visImageGrids(layer2Conv[0:32,:,:,:], winConv2, 'Layer2 Convolution output for ' + opt)\n",
    "        \n",
    "    visHeatMap(confusionMatrix, opt)\n",
    "        \n",
    "#         torch.save(model.state_dict(), \"checkpoints/model_\"+opt+'_'+reg+'_'+lossFn+'_'+nonLin+'.th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batchSize = 32\n",
    "testBatchSize = 256\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(datasets.CIFAR10('./data', \n",
    "                                                        train=True, \n",
    "                                                        download=True, \n",
    "                                                        transform=transforms.Compose([\n",
    "                                                            transforms.Resize((64,64)),\n",
    "                                                            transforms.RandomHorizontalFlip(),\n",
    "                                                            transforms.ToTensor(),\n",
    "                                                            transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "                                                        ])),\n",
    "                                          batch_size=batchSize, \n",
    "                                          shuffle=True, num_workers=0)\n",
    "testLoader = torch.utils.data.DataLoader(datasets.CIFAR10('./data', \n",
    "                                                        train=False, \n",
    "                                                        download=True, \n",
    "                                                        transform=transforms.Compose([\n",
    "                                                            transforms.Resize((64,64)),\n",
    "                                                            transforms.ToTensor(),\n",
    "                                                            transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "                                                        ])), \n",
    "                                          batch_size=testBatchSize, \n",
    "                                          shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "epochs = 35\n",
    "outputDims = 10\n",
    "\n",
    "optimizers = ['ADAM', 'SGD']\n",
    "\n",
    "winLine=[]\n",
    "winLine.append(viz.line(X=[0],Y=[0], name='ADAM', opts=dict(title='Training Loss', showlegend=True)))\n",
    "winLine.append(viz.line(X=[0],Y=[0], name='ADAM', opts=dict(title='Test Loss', showlegend=True)))\n",
    "winLine.append(viz.line(X=[0],Y=[0], name='ADAM', opts=dict(title='Test Accuracy', showlegend=True)))              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer = ADAM\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.307499\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 1.225101\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.348944\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 1.155937\n",
      "\n",
      "Test set: Average loss: 0.0041, Accuracy: 6302.0/10000 (63%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.030541\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 0.978600\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.167471\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 0.749379\n",
      "\n",
      "Test set: Average loss: 0.0034, Accuracy: 7014.0/10000 (70%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.133064\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 0.466322\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.835209\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 0.476715\n",
      "\n",
      "Test set: Average loss: 0.0032, Accuracy: 7251.0/10000 (73%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.652061\n",
      "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 0.610162\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.013661\n",
      "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 0.828796\n",
      "\n",
      "Test set: Average loss: 0.0030, Accuracy: 7403.0/10000 (74%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.970949\n",
      "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 1.020205\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.753192\n",
      "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 1.279985\n",
      "\n",
      "Test set: Average loss: 0.0029, Accuracy: 7512.0/10000 (75%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.943498\n",
      "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 0.479042\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.534506\n",
      "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 0.581427\n",
      "\n",
      "Test set: Average loss: 0.0027, Accuracy: 7699.0/10000 (77%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.458609\n",
      "Train Epoch: 7 [16000/50000 (32%)]\tLoss: 0.892790\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.240155\n",
      "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 0.966774\n",
      "\n",
      "Test set: Average loss: 0.0026, Accuracy: 7728.0/10000 (77%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.539765\n",
      "Train Epoch: 8 [16000/50000 (32%)]\tLoss: 0.922385\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.525163\n",
      "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 0.441942\n",
      "\n",
      "Test set: Average loss: 0.0026, Accuracy: 7736.0/10000 (77%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.564143\n",
      "Train Epoch: 9 [16000/50000 (32%)]\tLoss: 0.716446\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.619761\n",
      "Train Epoch: 9 [48000/50000 (96%)]\tLoss: 0.490672\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 7887.0/10000 (79%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.460532\n",
      "Train Epoch: 10 [16000/50000 (32%)]\tLoss: 0.621629\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.928953\n",
      "Train Epoch: 10 [48000/50000 (96%)]\tLoss: 0.884062\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 7921.0/10000 (79%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.676235\n",
      "Train Epoch: 11 [16000/50000 (32%)]\tLoss: 0.419725\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 0.693864\n",
      "Train Epoch: 11 [48000/50000 (96%)]\tLoss: 0.610581\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 8073.0/10000 (81%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.700614\n",
      "Train Epoch: 12 [16000/50000 (32%)]\tLoss: 0.562565\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 0.598762\n",
      "Train Epoch: 12 [48000/50000 (96%)]\tLoss: 0.690611\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 7998.0/10000 (80%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.463251\n",
      "Train Epoch: 13 [16000/50000 (32%)]\tLoss: 0.578746\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 0.522018\n",
      "Train Epoch: 13 [48000/50000 (96%)]\tLoss: 0.470654\n",
      "\n",
      "Test set: Average loss: 0.0025, Accuracy: 7854.0/10000 (79%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.455695\n",
      "Train Epoch: 14 [16000/50000 (32%)]\tLoss: 0.797854\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 0.639468\n",
      "Train Epoch: 14 [48000/50000 (96%)]\tLoss: 0.488871\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 7931.0/10000 (79%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.280251\n",
      "Train Epoch: 15 [16000/50000 (32%)]\tLoss: 0.570655\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 0.473017\n",
      "Train Epoch: 15 [48000/50000 (96%)]\tLoss: 0.454531\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8025.0/10000 (80%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.506549\n",
      "Train Epoch: 16 [16000/50000 (32%)]\tLoss: 0.504015\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 0.501045\n",
      "Train Epoch: 16 [48000/50000 (96%)]\tLoss: 0.538682\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 7919.0/10000 (79%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.475250\n",
      "Train Epoch: 17 [16000/50000 (32%)]\tLoss: 0.616746\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 0.631015\n",
      "Train Epoch: 17 [48000/50000 (96%)]\tLoss: 0.414524\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8085.0/10000 (81%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.536963\n",
      "Train Epoch: 18 [16000/50000 (32%)]\tLoss: 0.657489\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 0.885911\n",
      "Train Epoch: 18 [48000/50000 (96%)]\tLoss: 0.442928\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8109.0/10000 (81%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.510254\n",
      "Train Epoch: 19 [16000/50000 (32%)]\tLoss: 0.725146\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 0.838721\n",
      "Train Epoch: 19 [48000/50000 (96%)]\tLoss: 0.441473\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 8043.0/10000 (80%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.321754\n",
      "Train Epoch: 20 [16000/50000 (32%)]\tLoss: 0.635920\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 0.519029\n",
      "Train Epoch: 20 [48000/50000 (96%)]\tLoss: 0.497554\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 8019.0/10000 (80%)\n",
      "\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.559815\n",
      "Train Epoch: 21 [16000/50000 (32%)]\tLoss: 0.333126\n",
      "Train Epoch: 21 [32000/50000 (64%)]\tLoss: 0.485574\n",
      "Train Epoch: 21 [48000/50000 (96%)]\tLoss: 0.612298\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 8173.0/10000 (82%)\n",
      "\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.316451\n",
      "Train Epoch: 22 [16000/50000 (32%)]\tLoss: 0.466306\n",
      "Train Epoch: 22 [32000/50000 (64%)]\tLoss: 0.970303\n",
      "Train Epoch: 22 [48000/50000 (96%)]\tLoss: 0.561557\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 7910.0/10000 (79%)\n",
      "\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.458030\n",
      "Train Epoch: 23 [16000/50000 (32%)]\tLoss: 0.381387\n",
      "Train Epoch: 23 [32000/50000 (64%)]\tLoss: 0.385261\n",
      "Train Epoch: 23 [48000/50000 (96%)]\tLoss: 0.666502\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 8299.0/10000 (83%)\n",
      "\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.332699\n",
      "Train Epoch: 24 [16000/50000 (32%)]\tLoss: 0.446249\n",
      "Train Epoch: 24 [32000/50000 (64%)]\tLoss: 0.322156\n",
      "Train Epoch: 24 [48000/50000 (96%)]\tLoss: 0.490028\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8093.0/10000 (81%)\n",
      "\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.531834\n",
      "Train Epoch: 25 [16000/50000 (32%)]\tLoss: 0.696329\n",
      "Train Epoch: 25 [32000/50000 (64%)]\tLoss: 0.381698\n",
      "Train Epoch: 25 [48000/50000 (96%)]\tLoss: 0.760011\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8170.0/10000 (82%)\n",
      "\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.260800\n",
      "Train Epoch: 26 [16000/50000 (32%)]\tLoss: 0.427307\n",
      "Train Epoch: 26 [32000/50000 (64%)]\tLoss: 0.349122\n",
      "Train Epoch: 26 [48000/50000 (96%)]\tLoss: 0.402376\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 8213.0/10000 (82%)\n",
      "\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.187211\n",
      "Train Epoch: 27 [16000/50000 (32%)]\tLoss: 0.276883\n",
      "Train Epoch: 27 [32000/50000 (64%)]\tLoss: 0.359876\n",
      "Train Epoch: 27 [48000/50000 (96%)]\tLoss: 0.288708\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 8229.0/10000 (82%)\n",
      "\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.603079\n",
      "Train Epoch: 28 [16000/50000 (32%)]\tLoss: 0.347295\n",
      "Train Epoch: 28 [32000/50000 (64%)]\tLoss: 0.431073\n",
      "Train Epoch: 28 [48000/50000 (96%)]\tLoss: 0.521984\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 8258.0/10000 (83%)\n",
      "\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.410959\n",
      "Train Epoch: 29 [16000/50000 (32%)]\tLoss: 0.242225\n",
      "Train Epoch: 29 [32000/50000 (64%)]\tLoss: 0.584423\n",
      "Train Epoch: 29 [48000/50000 (96%)]\tLoss: 0.811006\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8127.0/10000 (81%)\n",
      "\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.234796\n",
      "Train Epoch: 30 [16000/50000 (32%)]\tLoss: 0.384295\n",
      "Train Epoch: 30 [32000/50000 (64%)]\tLoss: 0.314184\n",
      "Train Epoch: 30 [48000/50000 (96%)]\tLoss: 0.409199\n",
      "\n",
      "Test set: Average loss: 0.0020, Accuracy: 8278.0/10000 (83%)\n",
      "\n",
      "Train Epoch: 31 [0/50000 (0%)]\tLoss: 0.579423\n",
      "Train Epoch: 31 [16000/50000 (32%)]\tLoss: 0.308112\n",
      "Train Epoch: 31 [32000/50000 (64%)]\tLoss: 0.158949\n",
      "Train Epoch: 31 [48000/50000 (96%)]\tLoss: 0.323623\n",
      "\n",
      "Test set: Average loss: 0.0020, Accuracy: 8263.0/10000 (83%)\n",
      "\n",
      "Train Epoch: 32 [0/50000 (0%)]\tLoss: 0.608260\n",
      "Train Epoch: 32 [16000/50000 (32%)]\tLoss: 0.349917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32 [32000/50000 (64%)]\tLoss: 0.628999\n",
      "Train Epoch: 32 [48000/50000 (96%)]\tLoss: 0.520448\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 8196.0/10000 (82%)\n",
      "\n",
      "Train Epoch: 33 [0/50000 (0%)]\tLoss: 0.298938\n",
      "Train Epoch: 33 [16000/50000 (32%)]\tLoss: 0.397837\n",
      "Train Epoch: 33 [32000/50000 (64%)]\tLoss: 0.359746\n",
      "Train Epoch: 33 [48000/50000 (96%)]\tLoss: 0.582776\n",
      "\n",
      "Test set: Average loss: 0.0020, Accuracy: 8257.0/10000 (83%)\n",
      "\n",
      "Train Epoch: 34 [0/50000 (0%)]\tLoss: 0.385016\n",
      "Train Epoch: 34 [16000/50000 (32%)]\tLoss: 0.552436\n",
      "Train Epoch: 34 [32000/50000 (64%)]\tLoss: 0.375903\n",
      "Train Epoch: 34 [48000/50000 (96%)]\tLoss: 0.258715\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8134.0/10000 (81%)\n",
      "\n",
      "Train Epoch: 35 [0/50000 (0%)]\tLoss: 0.384601\n",
      "Train Epoch: 35 [16000/50000 (32%)]\tLoss: 0.349010\n",
      "Train Epoch: 35 [32000/50000 (64%)]\tLoss: 0.241106\n",
      "Train Epoch: 35 [48000/50000 (96%)]\tLoss: 0.268518\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8161.0/10000 (82%)\n",
      "\n",
      "Time required:49 minutes and 2 seconds\n",
      "-----------------------------------------\n",
      "Optimizer = SGD\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.275514\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 1.486851\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.310688\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 1.047538\n",
      "\n",
      "Test set: Average loss: 0.0046, Accuracy: 5940.0/10000 (59%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.200526\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 0.697286\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.964900\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 0.755684\n",
      "\n",
      "Test set: Average loss: 0.0036, Accuracy: 6856.0/10000 (69%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.892255\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 0.860813\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.125919\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 0.800982\n",
      "\n",
      "Test set: Average loss: 0.0033, Accuracy: 7230.0/10000 (72%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.823033\n",
      "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 0.876211\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.874603\n",
      "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 0.635513\n",
      "\n",
      "Test set: Average loss: 0.0031, Accuracy: 7342.0/10000 (73%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.550224\n",
      "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 0.744907\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.655547\n",
      "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 0.768588\n",
      "\n",
      "Test set: Average loss: 0.0031, Accuracy: 7376.0/10000 (74%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.525593\n",
      "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 0.551728\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.588725\n",
      "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 0.549034\n",
      "\n",
      "Test set: Average loss: 0.0030, Accuracy: 7443.0/10000 (74%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.471466\n",
      "Train Epoch: 7 [16000/50000 (32%)]\tLoss: 0.674767\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.615378\n",
      "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 0.519365\n",
      "\n",
      "Test set: Average loss: 0.0030, Accuracy: 7372.0/10000 (74%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.566532\n",
      "Train Epoch: 8 [16000/50000 (32%)]\tLoss: 0.653212\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.550436\n",
      "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 0.668199\n",
      "\n",
      "Test set: Average loss: 0.0029, Accuracy: 7499.0/10000 (75%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.708977\n",
      "Train Epoch: 9 [16000/50000 (32%)]\tLoss: 0.907275\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.642504\n",
      "Train Epoch: 9 [48000/50000 (96%)]\tLoss: 0.446290\n",
      "\n",
      "Test set: Average loss: 0.0027, Accuracy: 7683.0/10000 (77%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.469147\n",
      "Train Epoch: 10 [16000/50000 (32%)]\tLoss: 0.675966\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.565704\n",
      "Train Epoch: 10 [48000/50000 (96%)]\tLoss: 0.486523\n",
      "\n",
      "Test set: Average loss: 0.0026, Accuracy: 7723.0/10000 (77%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.442621\n",
      "Train Epoch: 11 [16000/50000 (32%)]\tLoss: 0.469515\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 0.545745\n",
      "Train Epoch: 11 [48000/50000 (96%)]\tLoss: 0.741630\n",
      "\n",
      "Test set: Average loss: 0.0025, Accuracy: 7820.0/10000 (78%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.550774\n",
      "Train Epoch: 12 [16000/50000 (32%)]\tLoss: 0.775316\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 0.724608\n",
      "Train Epoch: 12 [48000/50000 (96%)]\tLoss: 0.602738\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 7930.0/10000 (79%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.483499\n",
      "Train Epoch: 13 [16000/50000 (32%)]\tLoss: 0.354820\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 0.272550\n",
      "Train Epoch: 13 [48000/50000 (96%)]\tLoss: 0.426336\n",
      "\n",
      "Test set: Average loss: 0.0025, Accuracy: 7882.0/10000 (79%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.567352\n",
      "Train Epoch: 14 [16000/50000 (32%)]\tLoss: 0.735434\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 0.605993\n",
      "Train Epoch: 14 [48000/50000 (96%)]\tLoss: 0.445457\n",
      "\n",
      "Test set: Average loss: 0.0026, Accuracy: 7737.0/10000 (77%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.625015\n",
      "Train Epoch: 15 [16000/50000 (32%)]\tLoss: 0.558690\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 0.536946\n",
      "Train Epoch: 15 [48000/50000 (96%)]\tLoss: 0.415556\n",
      "\n",
      "Test set: Average loss: 0.0029, Accuracy: 7479.0/10000 (75%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.588372\n",
      "Train Epoch: 16 [16000/50000 (32%)]\tLoss: 0.563019\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 0.430816\n",
      "Train Epoch: 16 [48000/50000 (96%)]\tLoss: 0.676645\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8111.0/10000 (81%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.333315\n",
      "Train Epoch: 17 [16000/50000 (32%)]\tLoss: 0.510700\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 0.420475\n",
      "Train Epoch: 17 [48000/50000 (96%)]\tLoss: 0.442918\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 8031.0/10000 (80%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.478280\n",
      "Train Epoch: 18 [16000/50000 (32%)]\tLoss: 0.610585\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 0.446927\n",
      "Train Epoch: 18 [48000/50000 (96%)]\tLoss: 0.409801\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 7997.0/10000 (80%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.455693\n",
      "Train Epoch: 19 [16000/50000 (32%)]\tLoss: 0.413655\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 0.401426\n",
      "Train Epoch: 19 [48000/50000 (96%)]\tLoss: 0.437941\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8124.0/10000 (81%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.875641\n",
      "Train Epoch: 20 [16000/50000 (32%)]\tLoss: 0.376200\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 0.610652\n",
      "Train Epoch: 20 [48000/50000 (96%)]\tLoss: 0.440276\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 8186.0/10000 (82%)\n",
      "\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.270681\n",
      "Train Epoch: 21 [16000/50000 (32%)]\tLoss: 0.257677\n",
      "Train Epoch: 21 [32000/50000 (64%)]\tLoss: 0.420667\n",
      "Train Epoch: 21 [48000/50000 (96%)]\tLoss: 0.403145\n",
      "\n",
      "Test set: Average loss: 0.0027, Accuracy: 7712.0/10000 (77%)\n",
      "\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.655090\n",
      "Train Epoch: 22 [16000/50000 (32%)]\tLoss: 0.345072\n",
      "Train Epoch: 22 [32000/50000 (64%)]\tLoss: 0.625605\n",
      "Train Epoch: 22 [48000/50000 (96%)]\tLoss: 0.431818\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 8084.0/10000 (81%)\n",
      "\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.536935\n",
      "Train Epoch: 23 [16000/50000 (32%)]\tLoss: 0.567970\n",
      "Train Epoch: 23 [32000/50000 (64%)]\tLoss: 0.380830\n",
      "Train Epoch: 23 [48000/50000 (96%)]\tLoss: 0.472060\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 8227.0/10000 (82%)\n",
      "\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.239141\n",
      "Train Epoch: 24 [16000/50000 (32%)]\tLoss: 0.541366\n",
      "Train Epoch: 24 [32000/50000 (64%)]\tLoss: 0.374236\n",
      "Train Epoch: 24 [48000/50000 (96%)]\tLoss: 0.722306\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8144.0/10000 (81%)\n",
      "\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.507452\n",
      "Train Epoch: 25 [16000/50000 (32%)]\tLoss: 0.825365\n",
      "Train Epoch: 25 [32000/50000 (64%)]\tLoss: 0.320202\n",
      "Train Epoch: 25 [48000/50000 (96%)]\tLoss: 0.536474\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8128.0/10000 (81%)\n",
      "\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.429473\n",
      "Train Epoch: 26 [16000/50000 (32%)]\tLoss: 0.461743\n",
      "Train Epoch: 26 [32000/50000 (64%)]\tLoss: 0.558731\n",
      "Train Epoch: 26 [48000/50000 (96%)]\tLoss: 0.466564\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 8036.0/10000 (80%)\n",
      "\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.406077\n",
      "Train Epoch: 27 [16000/50000 (32%)]\tLoss: 0.473591\n",
      "Train Epoch: 27 [32000/50000 (64%)]\tLoss: 0.503804\n",
      "Train Epoch: 27 [48000/50000 (96%)]\tLoss: 0.557219\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8159.0/10000 (82%)\n",
      "\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.641433\n",
      "Train Epoch: 28 [16000/50000 (32%)]\tLoss: 0.544093\n",
      "Train Epoch: 28 [32000/50000 (64%)]\tLoss: 0.380801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28 [48000/50000 (96%)]\tLoss: 0.497760\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 7954.0/10000 (80%)\n",
      "\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.389001\n",
      "Train Epoch: 29 [16000/50000 (32%)]\tLoss: 0.402097\n",
      "Train Epoch: 29 [32000/50000 (64%)]\tLoss: 0.509910\n",
      "Train Epoch: 29 [48000/50000 (96%)]\tLoss: 0.392809\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8111.0/10000 (81%)\n",
      "\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.307455\n",
      "Train Epoch: 30 [16000/50000 (32%)]\tLoss: 0.293648\n",
      "Train Epoch: 30 [32000/50000 (64%)]\tLoss: 0.463932\n",
      "Train Epoch: 30 [48000/50000 (96%)]\tLoss: 0.653654\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 7971.0/10000 (80%)\n",
      "\n",
      "Train Epoch: 31 [0/50000 (0%)]\tLoss: 0.569016\n",
      "Train Epoch: 31 [16000/50000 (32%)]\tLoss: 0.492590\n",
      "Train Epoch: 31 [32000/50000 (64%)]\tLoss: 0.485519\n",
      "Train Epoch: 31 [48000/50000 (96%)]\tLoss: 0.405055\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 7872.0/10000 (79%)\n",
      "\n",
      "Train Epoch: 32 [0/50000 (0%)]\tLoss: 0.518963\n",
      "Train Epoch: 32 [16000/50000 (32%)]\tLoss: 0.358702\n",
      "Train Epoch: 32 [32000/50000 (64%)]\tLoss: 0.629941\n",
      "Train Epoch: 32 [48000/50000 (96%)]\tLoss: 0.437379\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8133.0/10000 (81%)\n",
      "\n",
      "Train Epoch: 33 [0/50000 (0%)]\tLoss: 0.335010\n",
      "Train Epoch: 33 [16000/50000 (32%)]\tLoss: 0.282500\n",
      "Train Epoch: 33 [32000/50000 (64%)]\tLoss: 0.602934\n",
      "Train Epoch: 33 [48000/50000 (96%)]\tLoss: 0.448881\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8156.0/10000 (82%)\n",
      "\n",
      "Train Epoch: 34 [0/50000 (0%)]\tLoss: 0.234552\n",
      "Train Epoch: 34 [16000/50000 (32%)]\tLoss: 0.630463\n",
      "Train Epoch: 34 [32000/50000 (64%)]\tLoss: 0.539268\n",
      "Train Epoch: 34 [48000/50000 (96%)]\tLoss: 0.409150\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8100.0/10000 (81%)\n",
      "\n",
      "Train Epoch: 35 [0/50000 (0%)]\tLoss: 0.251461\n",
      "Train Epoch: 35 [16000/50000 (32%)]\tLoss: 0.393136\n",
      "Train Epoch: 35 [32000/50000 (64%)]\tLoss: 0.244502\n",
      "Train Epoch: 35 [48000/50000 (96%)]\tLoss: 0.431388\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8009.0/10000 (80%)\n",
      "\n",
      "Time required:41 minutes and 59 seconds\n",
      "-----------------------------------------\n",
      "Wall time: 1h 31min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for idx in range(len(optimizers)):\n",
    "    startTime = time.time()\n",
    "    print('Optimizer = '+ optimizers[idx])\n",
    "    evalModel(lr, optimizers[idx], batchSize, outputDims, winLine)\n",
    "    endTime = time.time()\n",
    "    print('Time required:{} minutes and {} seconds'.format(int((endTime-startTime)/60), \n",
    "                                                           int((endTime-startTime)%60)))\n",
    "    print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**: Augmenting the dataset by flipping the images and upscaling them to twice their original size improves the accuracy considerably. The overall performance using both SGD and ADAM were similar. However with Adam, the risk of overfitting/underfiiting seemed greater as the weight decay term needed a lot of tuning. The dropout was removed from the convolution layer, However without it, some of the filters do not seem to be learning anything useful and just produve a black box."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
